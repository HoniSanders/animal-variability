{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file contains all functions that are called in the main code and revisions jupyter notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynwb import TimeSeries\n",
    "from datetime import datetime\n",
    "from dateutil.tz import tzlocal\n",
    "from pynwb import NWBFile\n",
    "import numpy as np\n",
    "from pynwb import NWBHDF5IO\n",
    "import h5py\n",
    "#from pynwb import h5py\n",
    "import pynwb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import math\n",
    "from scipy import stats\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import os, sys\n",
    "import scipy\n",
    "from pydoc import help\n",
    "from scipy.stats.stats import pearsonr\n",
    "import importnb\n",
    "\n",
    "\n",
    "\n",
    "def get_session_data(session_name, dictionary, num_cells):\n",
    "    #A function that loops over the keys of a dictionary and orders the data in 3darrays.\n",
    "    #The dictionary keys are session names, the dictionary values are 2d arrays of the activity of a given cell \n",
    "    #in that particular enviornment. This function orders the data of sessions in 3d arrays where the z-coordinate\n",
    "    #is the cell number. Session data that is missing is flagged with a 3darray on ones. \n",
    "    \n",
    "    ordered_data = np.ones(shape=(num_cells,20,20))\n",
    "    for i in dictionary:\n",
    "        \n",
    "        if i[6:16] == session_name: \n",
    "            try: \n",
    "                ordered_data[int(i[17:19]),:,:] = dictionary[i]\n",
    "            except ValueError:\n",
    "                ordered_data[int(i[17]),:,:] = dictionary[i]\n",
    "                \n",
    "   \n",
    "        elif i[6:19] == session_name:\n",
    "            try: \n",
    "                ordered_data[ int(i[20:22]),:, :] = dictionary[i]\n",
    "            except ValueError:\n",
    "                ordered_data[int(i[20]),:,:] = dictionary[i] \n",
    "            \n",
    "               \n",
    "        elif i[6:20] == session_name: \n",
    "            try:\n",
    "                ordered_data[int(i[21:23]),:,:] = dictionary[i]\n",
    "            \n",
    "            except ValueError:\n",
    "                ordered_data[int(i[21]),:,:] = dictionary[i]\n",
    "    \n",
    "    return ordered_data\n",
    "\n",
    "def remove_missing_data(dictionary, num_cell):\n",
    "    #A function that takes in a dictionary of 3darrays and removes flagged arrays by converting them to empty lists\n",
    "    #this function is unique to the syntax of the Alme_final code. the get_session_data function flags missing data \n",
    "    #by filling in the value of the dictionary with a 3darray of ones. \n",
    "    for i in dictionary: \n",
    "        if np.all(dictionary[i][0] == 1):\n",
    "            dictionary[i] =[]\n",
    "    return dictionary\n",
    "            \n",
    "\n",
    "\n",
    "def remove_outer_list(dictionary):\n",
    "    #A function that takes in a dictionary and removes the outer list of the values, if the values are in a list \n",
    "    for key in dictionary: \n",
    "        if len(dictionary[key]) == 1:\n",
    "            dictionary[key]= dictionary[key][0]\n",
    "    return dictionary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to identify and match repeated and different sessions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_different_sessions(a):\n",
    "    #A function that returns the different session pair of the input session\n",
    "    #Different session pair means all potential combinations with other sessions that are different\n",
    "    #It is expected to loop over the keys of the dictionary below. \n",
    "    #Repetions are removed! When we input a='F1' we make a comparison with 'N1', so when we input a='N1', 'F1'\n",
    "    #does not appear anymore to prevent double counting.\n",
    "    \n",
    "    diff_sess = {'F1': ['N1','N1!','N2','N2!','N3','N3!','N4','N4!','N5','N5!','N6','N6!', 'N1*', 'N1*!',\n",
    "                       'N7','N7!', 'N8','N8!','N9','N9!','N10','N10!', 'N6*', 'N6*!'],\n",
    "                 \n",
    "                 'N1': ['F1*','F2','F2*','N2','N2!','N3','N3!','N4','N4!','N5','N5!','N6','N6!',\n",
    "                       'N7','N7!', 'N8','N8!','N9','N9!','N10','N10!', 'N6*', 'N6*!'],\n",
    "                 \n",
    "                 'N1!': ['F1*','F2','F2*','N2','N2!','N3','N3!','N4','N4!','N5','N5!','N6','N6!',\n",
    "                       'N7','N7!', 'N8','N8!','N9','N9!','N10','N10!', 'N6*', 'N6*!'],\n",
    "                \n",
    "                 'N2': ['F1*','F2','F2*','N3','N3!','N4','N4!','N5','N5!','N6','N6!','N1*', 'N1*!',\n",
    "                       'N7','N7!', 'N8','N8!','N9','N9!','N10','N10!', 'N6*', 'N6*!'],\n",
    "                 \n",
    "                 'N2!': ['F1*','F2','F2*','N3','N3!','N4','N4!','N5','N5!','N6','N6!','N1*', 'N1*!',\n",
    "                       'N7','N7!', 'N8','N8!','N9','N9!','N10','N10!', 'N6*', 'N6*!'],\n",
    "                 \n",
    "                 'N3': ['F1*','F2','F2*','N4','N4!','N5','N5!','N6','N6!','N1*', 'N1*!',\n",
    "                       'N7','N7!', 'N8','N8!','N9','N9!','N10','N10!', 'N6*', 'N6*!'],\n",
    "                 \n",
    "                 'N3!': ['F1*','F2','F2*','N4','N4!','N5','N5!','N6','N6!','N1*', 'N1*!',\n",
    "                       'N7','N7!', 'N8','N8!','N9','N9!','N10','N10!', 'N6*', 'N6*!'],\n",
    "                 \n",
    "                 'N4': ['F1*','F2','F2*','N5','N5!','N6','N6!','N1*', 'N1*!',\n",
    "                        'N7','N7!', 'N8','N8!','N9','N9!','N10','N10!','N6*', 'N6*!'],\n",
    "                 \n",
    "                 'N4!': ['F1*','F2','F2*','N5','N5!','N6','N6!','N1*', 'N1*!',\n",
    "                        'N7','N7!', 'N8','N8!','N9','N9!','N10','N10!','N6*', 'N6*!'],\n",
    "            \n",
    "                 'N5': ['F1*','F2','F2*','N6','N6!','N1*', 'N1*!',\n",
    "                        'N7','N7!', 'N8','N8!','N9','N9!','N10','N10!','N6*', 'N6*!'],\n",
    "                 'N5!': ['F1*','F2','F2*','N6','N6!','N1*', 'N1*!',\n",
    "                        'N7','N7!', 'N8','N8!','N9','N9!','N10','N10!','N6*', 'N6*!'],\n",
    "                 \n",
    "                 'N1*': ['F1*','F2','F2*','N6','N6!','N7','N7!', 'N8','N8!','N9','N9!','N10','N10!','N6*', 'N6*!'],\n",
    "                 'N1*!': ['F1*','F2','F2*','N6','N6!','N7','N7!', 'N8','N8!','N9','N9!','N10','N10!','N6*', 'N6*!'], \n",
    "                 \n",
    "                 'F1*': ['N6','N6!','N7','N7!', 'N8','N8!','N9','N9!','N10','N10!','N6*', 'N6*!'], \n",
    "                 \n",
    "                 'F2': ['N6','N6!','N7','N7!', 'N8','N8!','N9','N9!','N10','N10!','N6*', 'N6*!'], \n",
    "                 \n",
    "                 'N6': ['F2*','N7','N7!', 'N8','N8!','N9','N9!','N10','N10!'],  \n",
    "                 'N6!': ['F2*','N7','N7!', 'N8','N8!','N9','N9!','N10','N10!'],  \n",
    "                 \n",
    "                 'N7': ['F2*','N8','N8!','N9','N9!','N10','N10!','N6*', 'N6*!'],\n",
    "                 'N7!':['F2*','N8','N8!','N9','N9!','N10','N10!','N6*', 'N6*!'],\n",
    "                 \n",
    "                 'N8': ['F2*','N9','N9!','N10','N10!','N6*', 'N6*!'],\n",
    "                 'N8!': ['F2*','N9','N9!','N10','N10!', 'N6*', 'N6*!'],\n",
    "                 \n",
    "                 'N9': ['F2*','N10','N10!','N6*', 'N6*!'],\n",
    "                 'N9!': ['F2*','N10','N10!','N6*', 'N6*!'],\n",
    "                \n",
    "                 'N10': ['F2*','N6*', 'N6*!'],\n",
    "                 'N10!': ['F2*','N6*', 'N6*!'],\n",
    "                   \n",
    "                 'N6*': ['F2*'], \n",
    "                 'N6*!': ['F2*']}\n",
    "                 \n",
    "    return diff_sess[a]\n",
    "\n",
    "def all_repeated_sessions(session): \n",
    "    #A function that returns the repeated session pair of the input session \n",
    "    rep_sess_combi={'F1':  ['F1*','F2','F2*'],\n",
    "                    'N1':  ['N1!','N1*','N1*!'],\n",
    "                    'N1!': ['N1*','N1*!'],\n",
    "                    'N2':  ['N2!'], \n",
    "                    'N3':  ['N3!'], \n",
    "                    'N4':  ['N4!'],\n",
    "                    'N1*': ['N1*!'],\n",
    "                    'F1*': ['F2', 'F2*'],\n",
    "                    'F2':  ['F2*'],\n",
    "                    'N5':  ['N5!'],\n",
    "                    'N6':  ['N6!','N6*','N6*!'],\n",
    "                    'N6!': ['N6*','N6*!'],\n",
    "                    'N7':  ['N7!'],\n",
    "                    'N8':  ['N8!'],\n",
    "                    'N9':  ['N9!'],\n",
    "                    'N10': ['N10!'],\n",
    "                    'N6*': ['N6*!']}\n",
    "    return rep_sess_combi[session] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to compute Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specific_rate_map_corr(session1, session2, data):\n",
    "    ###used to get RMCs of individual cells in figure 3 ONLY. Not used for \n",
    "    result = []                             #list of rate_map_corr but only the ones we are interested in \n",
    "    \n",
    "    for cell in range(len(data[session1])):      #for each cell... \n",
    "        rm1 = data[session1][cell]               #get the rate map in session 1\n",
    "        rm2 = data[session2][cell]               #get the rate map in session 2\n",
    "        th1 = thresholds[session1][str(cell)]    #get the threshold_description in session 1\n",
    "        th2 = thresholds[session2][str(cell)]    #get the threshold_description in session 1\n",
    "        num_bins = rm1.shape[0]                  #should be 20 bins\n",
    "        rm1 = np.reshape(rm1, num_bins**2)       #reshape the rate maps \n",
    "        rm2 = np.reshape(rm2, num_bins**2)\n",
    "        result.append(pearsonr(rm1,rm2)[0])\n",
    "    return result\n",
    "\n",
    "def pv_dot(vec1, vec2): \n",
    "    #a function that takes in two 1d_arrays and returns the dot product divided by the number of elements that are\n",
    "    #not nans        \n",
    "    #vec1 = np.nan_to_num(vec1)\n",
    "    #vec2 = np.nan_to_num(vec1)\n",
    "    corr_t = []\n",
    "    for x in range(vec1.shape[1]): \n",
    "        for y in range(vec1.shape[2]): \n",
    "            mask = ~np.isnan(vec1[:,x,y]) * ~np.isnan(vec2[:,x,y]) #a mask of positions where both vectors have values that are not nan\n",
    "            corr = np.dot(vec1[mask, x, y] ,vec2[mask, x, y])/len(mask)#the dot product of the selected positions divided by the length\n",
    "            #corr = np.dot(vec1[mask, x, y] ,vec2[mask, x, y])\n",
    "            corr_t.append(corr)\n",
    "    return corr_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_rate_map_corr(session1, session2, data, thresholds):\n",
    "    #A function that takes in two 3d_arrays and the thresholds and returns a vector of Rate_map correlations \n",
    "    #this fuction is intelligent meaning that it can distinguish which rate_map correlations to include and which not\n",
    "    #the knowledge of this comes from thresholds, which is a dictionary \n",
    "    #thresholds = dictionary    Key1 = Session name, Key2 = cell, value = threshold_classification \n",
    "    \n",
    "    \n",
    "    result = []                             #list of rate_map_corr but only the ones we are interested in \n",
    "    \n",
    "    counters = {'above_above': 0, 'above_below': 0, 'above_zero': 0, \n",
    "                'zero_zero': 0, 'below_zero': 0, 'below_below':0,\n",
    "                'total': 0}\n",
    "    \n",
    "    \n",
    "    for cell in range(len(data[session1])):      #for each cell... \n",
    "        counters['total'] = counters['total']+1  #count each cell, total number of observations \n",
    "        rm1 = data[session1][cell]               #get the rate map in session 1\n",
    "        rm2 = data[session2][cell]               #get the rate map in session 2\n",
    "        th1 = thresholds[session1][str(cell)]    #get the threshold_description in session 1\n",
    "        th2 = thresholds[session2][str(cell)]    #get the threshold_description in session 1\n",
    "        num_bins = rm1.shape[0]                  #should be 20 bins\n",
    "        rm1 = np.reshape(rm1, num_bins**2)       #reshape the rate maps \n",
    "        rm2 = np.reshape(rm2, num_bins**2)\n",
    "    \n",
    "    #############################################################################\n",
    "    # there are 6 thresholding cases and we treat some of them differently.     #\n",
    "    #############################################################################\n",
    "        \n",
    "        #These are the cases that we use: \n",
    "        \n",
    "        \n",
    "        #Case 1: the cell spiked in both sessions above threshold \n",
    "        if th1 == True and th2 == True:    \n",
    "            result.append(pearsonr(rm1,rm2)[0])    #get the Pearsonr\n",
    "            counters['above_above'] = counters['above_above']+1\n",
    "        \n",
    "        \n",
    "        #Case 2: the cell spiked above threshold in one session and below threshold in the other \n",
    "        if th1 == True and th2 == False:\n",
    "            result.append(pearsonr(rm1,rm2)[0])    #get the Pearsonr\n",
    "            counters['above_below'] = counters['above_below']+1\n",
    "        if th1 == False and th2 == True:\n",
    "            result.append(pearsonr(rm1,rm2)[0])    #get the Pearsonr\n",
    "            counters['above_below'] = counters['above_below']+1\n",
    "            \n",
    "        #Case 3: The cell spiked above threshold in one session and was silent in the other\n",
    "        if th1 == True and th2 == 'silent':\n",
    "            result.append(0)                       #input 0 as corr_coeff\n",
    "            counters['above_zero'] = counters['above_zero']+1\n",
    "        if th1 == 'silent' and th2 == True:\n",
    "            result.append(0)                       #input 0 as corr_coeff\n",
    "            counters['above_zero'] = counters['above_zero']+1\n",
    "        \n",
    "        #Case 4: cell was silent in both sessions \n",
    "        if th1 == 'silent' and th2 == 'silent':\n",
    "            counters['zero_zero'] = counters['zero_zero']+1\n",
    "        \n",
    "        \n",
    "        #Case 5: cell was silent in one and below th in the other \n",
    "        if th1 == 'silent' and th2 == False:\n",
    "            counters['below_zero'] = counters['below_zero']+1\n",
    "        if th1 == False and th2 == 'silent':\n",
    "            counters['below_zero'] = counters['below_zero']+1\n",
    "        \n",
    "        #Case 6: cell was below threshold in both sessions \n",
    "        if th1 == False and th2 == False:\n",
    "            counters['below_below'] = counters['below_below']+1\n",
    "        \n",
    "        \n",
    "        #Case 4: cell was silent in both session, \n",
    "        #Case 5: cell was below threshold in both sessions, \n",
    "        #Case 6: cell was below threshold in one session and silent in the other \n",
    "       \n",
    "    \n",
    "    return result,counters\n",
    "\n",
    "\n",
    "\n",
    "def int_rate_map_corr_2(session1, session2, data, thresholds):\n",
    "    #A function that takes in two 3d_arrays and the thresholds and returns a vector of Rate_map correlations \n",
    "    #this fuction is intelligent meaning that it can distinguish which rate_map correlations to include and which not\n",
    "    #the knowledge of this comes from thresholds, which is a dictionary \n",
    "    #thresholds = dictionary    Key1 = Session name, Key2 = cell, value = threshold_classification \n",
    "    #Returns also case. Description of corresponding case \n",
    "    ###USED FOR HISTOGRAMS###\n",
    "    \n",
    "    result = []                             #list of rate_map_corr but only the ones we are interested in \n",
    "    case   = []\n",
    "    counter = 0                             #counts all cases \n",
    "    \n",
    "    for cell in range(len(data[session1])):             #for each cell... \n",
    "        counter = counter + 1\n",
    "        rm1 = data[session1][cell]               #get the rate map in session 1\n",
    "        rm2 = data[session2][cell]               #get the rate map in session 2\n",
    "        th1 = thresholds[session1][str(cell)]    #get the threshold_description in session 1\n",
    "        th2 = thresholds[session2][str(cell)]    #get the threshold_description in session 1\n",
    "        num_bins = rm1.shape[0]                  #should be 20 bins\n",
    "        rm1 = np.reshape(rm1, num_bins**2)       #reshape the rate maps \n",
    "        rm2 = np.reshape(rm2, num_bins**2)\n",
    "    \n",
    "    #############################################################################\n",
    "    # there are 6 thresholding cases and we treat some of them differently.     #\n",
    "    #############################################################################\n",
    "        \n",
    "        #These are the cases that we use: \n",
    "        \n",
    "        \n",
    "        #Case 1: the cell spiked in both sessions above threshold \n",
    "        \n",
    "        if th1 == True and th2 == True:    \n",
    "            result.append(pearsonr(rm1,rm2)[0])    #get the Pearsonr\n",
    "            case.append('above_above')\n",
    "        #Case 2: the cell spiked above threshold in one session and below threshold in the other \n",
    "        \n",
    "        if th1 == True and th2 == False:\n",
    "            result.append(pearsonr(rm1,rm2)[0])    #get the Pearsonr\n",
    "            case.append('above_below')\n",
    "        \n",
    "        if th1 == False and th2 == True:\n",
    "            result.append(pearsonr(rm1,rm2)[0])    #get the Pearsonr\n",
    "            case.append('above_below')\n",
    "            \n",
    "        #Case 3: The cell spiked above threshold in one session and was silent in the other\n",
    "        if th1 == True and th2 == 'silent':\n",
    "            result.append(0)                       #input 0 as corr_coeff\n",
    "            case.append('above_zero')\n",
    "        if th1 == 'silent' and th2 == True:\n",
    "            result.append(0)                       #input 0 as corr_coeff\n",
    "            case.append('above_zero')\n",
    "    \n",
    "        #Case 4: cell was silent in both session, \n",
    "        #Case 5: cell was below threshold in both sessions, \n",
    "        #Case 6: cell was below threshold in one session and silent in the other \n",
    "        #-----> we ignore these cases\n",
    "    #print(counter)\n",
    "    excluded = counter - len(result)\n",
    "\n",
    "    return result,case,excluded\n",
    "\n",
    "\n",
    "    \n",
    "def get_corr_coeff(comparisons, data): \n",
    "    # a function that takes in a dictionary and data and returns the correct correlation coefficients in a list\n",
    "    # Data = 28 * 28 matrix with each cell representing a correlation coefficient between two rooms \n",
    "     \n",
    "        dic = {'F1':  0,                      #conversions of sessions to indeces \n",
    "            'N1':  1, 'N1!': 2,\n",
    "            'N2':  3, 'N2!': 4,\n",
    "            'N3':  5, 'N3!': 6, \n",
    "            'N4':  7, 'N4!': 8,\n",
    "            'N5':  9, 'N5!': 10, \n",
    "            'N1*': 11, 'N1*!':12,\n",
    "            'F1*': 13, \n",
    "            'F2':  14, \n",
    "            'N6':  15, 'N6!': 16,\n",
    "            'N7':  17, 'N7!': 18, \n",
    "            'N8':  19, 'N8!': 20, \n",
    "            'N9':  21, 'N9!': 22,\n",
    "            'N10': 23, 'N10!':24,  \n",
    "            'N6*': 25, 'N6*!':26,\n",
    "            'F2*': 27}\n",
    "\n",
    "        corr_coeff_all = []\n",
    "        \n",
    "        for session_1 in list(comparisons.keys()):\n",
    "            for session_2 in comparisons[session_1]:\n",
    "                corr_coeff = data[dic[session_1]][dic[session_2]]\n",
    "                corr_coeff_all.append(corr_coeff)\n",
    "                \n",
    "        return corr_coeff_all\n",
    "                \n",
    "                \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Averaging between animals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_average(mat_1, mat_2, mat_3, mat_4, mat_5): \n",
    "    #A function that takes in 5 2D matrices and builds an average matrix of the values involved.\n",
    "    #the matrices must all be the same x and y dimensions. x and y are the sessions that were correlated. \n",
    "    #This funtions is used to average the correlation plots of Part 6 in Part 7\n",
    "    #the five animals. The function returns the average martix. \n",
    "    \n",
    "    y = mat_1.shape[0]                     #extract the length of the y-axis\n",
    "    x = mat_1.shape[1]                     #extract the length of the x-axis \n",
    "    cum_mat = np.ndarray(shape=(5, y, x))  #this is a data holder matrix where the z dimension will correspond to \n",
    "                                           #the matrices that we input and want to average \n",
    "    average = np.zeros(shape=(y,x))        #this 2D matrix will hold our average data\n",
    "    \n",
    "    cum_mat[0] = mat_1 #Put the input matrixes into the cum_mat data holder \n",
    "    cum_mat[1] = mat_2\n",
    "    cum_mat[2] = mat_3\n",
    "    cum_mat[3] = mat_4\n",
    "    cum_mat[4] = mat_5\n",
    "    for y_ in range(y):                                   #for each row... \n",
    "        for x_ in range(x):                               #for each element in that row...\n",
    "            average[y_,x_] = np.nanmean(cum_mat[:,y_,x_]) #the average value is computed along the z axis. \n",
    "                                                          #nans are not taken into account.       \n",
    "    return average     #Return the average 2D matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohen_d(x,y):\n",
    "    nx = len(x)\n",
    "    ny = len(y)\n",
    "    dof = nx + ny - 2\n",
    "    s =  np.sqrt(((nx-1)*np.std(x, ddof=1) ** 2 + (ny-1)*np.std(y, ddof=1) ** 2) / dof)\n",
    "    return (np.mean(x) - np.mean(y)) / s\n",
    "\n",
    "\n",
    "\n",
    "def get_value(animal,sessions, data): \n",
    "    # a function that takes in a list of sessions and data and returns the correct diff in a list\n",
    "    # Data = dictionary of dictionaries, key 1 = animal, key 2 = session, value = behavioral metric\n",
    "    result = []\n",
    "    \n",
    "    for s in sessions: \n",
    "        result.append(data[s])\n",
    "        \n",
    "    return np.mean(result)\n",
    "\n",
    "\n",
    "def get_diff(comparisons, data): \n",
    "    # a function that takes in a dictionary and data and returns the correct diff in a list\n",
    "    # Data = 28 * 28 matrix with each cell representing a difference in a behavioral metric between two rooms \n",
    "     \n",
    "        dic = {'F1':  0,                      #conversions of sessions to indeces \n",
    "               'N1':  1, 'N1!': 2,\n",
    "               'N2':  3, 'N2!': 4,\n",
    "               'N3':  5, 'N3!': 6, \n",
    "               'N4':  7, 'N4!': 8,\n",
    "               'N5':  9, 'N5!': 10, \n",
    "               'N1*': 11, 'N1*!':12,\n",
    "               'F1*': 13, \n",
    "               'F2':  14, \n",
    "               'N6':  15, 'N6!': 16,\n",
    "               'N7':  17, 'N7!': 18, \n",
    "               'N8':  19, 'N8!': 20, \n",
    "               'N9':  21, 'N9!': 22,\n",
    "               'N10': 23, 'N10!':24,  \n",
    "               'N6*': 25, 'N6*!':26,\n",
    "               'F2*': 27}\n",
    "\n",
    "        diff = []\n",
    "        \n",
    "        for session_1 in list(comparisons.keys()):\n",
    "            for session_2 in comparisons[session_1]:\n",
    "                diff_sess = data[dic[session_1]][dic[session_2]]\n",
    "                diff.append(diff_sess)\n",
    "                \n",
    "        return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_counter(session1, session2,animal, thresholds):\n",
    "    #A function that takes in two session names, the name of an and  animal  a dictionary of thresholds \n",
    "    #and counts how many cells are above threshold etc \n",
    "    #thresholds = dictionary    Key1 = animal name, Key2 = session name , Key3 = cell name \n",
    "    #value = threshold_classification \n",
    "     \n",
    "    case   = []\n",
    "    counter = 0                             #counts all cases \n",
    "    \n",
    "    num_cell = len(thresholds[animal][session1])\n",
    "    \n",
    "    cells_above_above = 0\n",
    "    cells_above_below = 0\n",
    "    for cell in range(len(thresholds[animal][session1])):             #for each cell... \n",
    "        counter = counter + 1\n",
    "        th1 = thresholds[animal][session1][str(cell)]    #get the threshold_description in session 1\n",
    "        th2 = thresholds[animal][session2][str(cell)]    #get the threshold_description in session 1  \n",
    "    #############################################################################\n",
    "    # there are 6 thresholding cases and we treat some of them differently.     #\n",
    "    #############################################################################\n",
    "        \n",
    "        #These are the cases that we use: \n",
    "        \n",
    "        \n",
    "        #Case 1: the cell spiked in both sessions above threshold \n",
    "        \n",
    "        if th1 == True and th2 == True:    \n",
    "            case.append('above_above')\n",
    "            cells_above_above = cells_above_above+1\n",
    "        #Case 2: the cell spiked above threshold in one session and below threshold in the other \n",
    "        \n",
    "        if th1 == True and th2 == False:\n",
    "            case.append('above_below')\n",
    "            cells_above_below = cells_above_below +1\n",
    "        \n",
    "        if th1 == False and th2 == True:\n",
    "            case.append('above_below')\n",
    "            cells_above_below = cells_above_below +1\n",
    "            \n",
    "        #Case 3: The cell spiked above threshold in one session and was silent in the other\n",
    "        if th1 == True and th2 == 'silent':     \n",
    "            case.append('above_zero')\n",
    "            cells_above_below = cells_above_below +1\n",
    "        \n",
    "        if th1 == 'silent' and th2 == True:\n",
    "            cells_above_below = cells_above_below +1\n",
    "            case.append('above_zero')\n",
    "    \n",
    "        #Case 4: cell was silent in both session, \n",
    "        #Case 5: cell was below threshold in both sessions, \n",
    "        #Case 6: cell was below threshold in one session and silent in the other \n",
    "        #-----> we ignore these cases\n",
    "    #print(counter)\n",
    "    \n",
    "    #excluded = counter - len(result)\n",
    "    fraction_above = cells_above_above/num_cell * 100\n",
    "    fraction_above_below = cells_above_below/num_cell * 100\n",
    "    fraction_below_below = 100- fraction_above_below - fraction_above\n",
    "\n",
    "    return case, fraction_above, fraction_above_below, fraction_below_below"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
